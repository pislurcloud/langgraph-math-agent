# LangGraph Math Agent

An intelligent agent built with LangGraph that seamlessly handles both mathematical operations and general knowledge queries using LLM reasoning.

## ğŸ¯ Features

- **Intelligent Query Routing**: Automatically detects mathematical vs. general queries
- **Custom Math Tools**: Addition, subtraction, multiplication, and division
- **LLM Integration**: Uses Groq's meta-llama/llama-4-scout-17b-16e-instruct model
- **Error Handling**: Includes validation for edge cases (e.g., division by zero)
- **Graph-Based Architecture**: Built using LangGraph's StateGraph
- **âœ¨ Interactive Conversations**: Full conversation memory with ongoing dialogue support
- **âœ¨ Context-Aware Responses**: Remembers previous questions and answers
- **âœ¨ User-Friendly Interface**: Real-time input with graceful exit options
- **âœ¨ Graph Visualization**: Automatic generation of workflow diagram

## ğŸ“‹ Prerequisites

- Python 3.8 or higher
- Groq API key ([Get one here](https://console.groq.com/keys))

## ğŸš€ Quick Start

### 1. Clone or Download Files

Ensure you have the following files:
- `langgraph_math_agent.py` (main implementation)
- `requirements.txt` (dependencies)
- `.env.example` (environment template)
- `REPORT.md` (detailed documentation)

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Configure API Key

Create a `.env` file in the project directory:

```bash
cp .env.example .env
```

Edit `.env` and add your Groq API key:

```
GROQ_API_KEY=your_actual_api_key_here
```

### 4. Run the Agent

**Interactive Mode (Default):**
```bash
python langgraph_math_agent.py
```

This launches an interactive conversation where you can:
- Ask unlimited questions
- Have ongoing conversations with memory
- Exit anytime with `<QUIT>` or `Ctrl+C`

**Demo Mode:**
```bash
python langgraph_math_agent.py --demo
```

This runs predefined test queries to demonstrate capabilities.

## ğŸ’¬ Interactive Conversation

The agent now supports full conversation memory! Here's an example:

```
You: What is 15 plus 7?
Agent: 15 plus 7 equals 22

You: Multiply that by 3
Agent: 22 multiplied by 3 equals 66

You: What was my first question?
Agent: Your first question was "What is 15 plus 7?"

You: What is the capital of France?
Agent: The capital of France is Paris

You: <QUIT>
ğŸ‘‹ Thank you for chatting! Goodbye!
```

The agent remembers the entire conversation context, allowing for natural follow-up questions!

## ğŸ’¡ Usage Examples

The agent can handle both mathematical and general queries with full conversation memory:

### Mathematical Queries
```
"What is 25 plus 17?"
"Calculate 100 minus 45"
"What is 8 multiplied by 7?"
"Divide 144 by 12"
```

### General Queries
```
"What is the capital of France?"
"Explain what artificial intelligence is"
"Who wrote Romeo and Juliet?"
```

### Follow-up Questions (Using Memory)
```
"What is 10 plus 5?"
â†’ "Now multiply that by 2"
â†’ "What was the first number I mentioned?"
```

## ğŸ“Š Architecture

```
START â†’ CHATBOT (LLM) â†’ [TOOLS or END]
                â†‘            â†“
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The agent uses a graph-based architecture:
1. **Chatbot Node**: LLM analyzes the query
2. **Conditional Routing**: Decides if tools are needed
3. **Tools Node**: Executes mathematical operations
4. **Feedback Loop**: Returns to chatbot for final response

**Visual Representation:**  
When you run the agent, it automatically generates graph visualizations in two formats:
- **Mermaid text file** (`.mmd`) - Always works, can be viewed at [mermaid.live](https://mermaid.live/edit)
- **PNG image** (`.png`) - Optional, requires system graphviz (no extra setup needed if installation succeeded) This shows the complete workflow with all nodes, edges, and routing logic.

## ğŸ“š Documentation

For detailed implementation explanation, see [REPORT.md](REPORT.md) which includes:
- Architecture overview
- LLM integration details
- Complete code breakdown
- Program flow explanation
- Example outputs

**Having issues with graph visualization?** See [TROUBLESHOOTING_GRAPH_VIZ.md](TROUBLESHOOTING_GRAPH_VIZ.md)

## ğŸ› ï¸ Technical Stack

- **LangGraph**: Graph-based agent framework
- **LangChain**: LLM integration and tool management
- **Groq API**: Fast LLM inference
- **Python**: Core implementation

## ğŸ“ Assignment Details

This project is part of the Analytics Vidhya "Building Advanced AI Agents with LangGraph" assignment.

**Key Requirements Met:**
- âœ… Custom mathematical functions (plus, subtract, multiply, divide)
- âœ… LLM integration for general queries
- âœ… Graph-based architecture with conditional routing
- âœ… Tool binding and execution
- âœ… Error handling
- âœ… Comprehensive documentation
- âœ… **Interactive conversation mode with full memory**
- âœ… **Dynamic user input with graceful exit**
- âœ… **Context-aware responses for follow-up questions**

## ğŸ” Code Structure

```
langgraph_math_agent.py
â”œâ”€â”€ Custom Functions (@tool decorators)
â”‚   â”œâ”€â”€ plus(a, b)
â”‚   â”œâ”€â”€ subtract(a, b)
â”‚   â”œâ”€â”€ multiply(a, b)
â”‚   â””â”€â”€ divide(a, b)
â”œâ”€â”€ State Schema (AgentState)
â”œâ”€â”€ LLM Setup (Groq with tool binding)
â”œâ”€â”€ Graph Nodes
â”‚   â”œâ”€â”€ chatbot(state)
â”‚   â””â”€â”€ tool_node
â”œâ”€â”€ Routing Logic (should_continue)
â”œâ”€â”€ Graph Construction (create_graph)
â””â”€â”€ Demo Function (main)
```

## ğŸ“ Learning Outcomes

This project demonstrates:
- Building agentic systems with LangGraph
- Integrating LLMs with custom tools
- Implementing conditional routing
- Managing state in multi-step workflows
- Production-ready error handling

## ğŸ“„ License

This is an educational project for Analytics Vidhya assignment.

## ğŸ™‹ Support

For questions about the implementation, refer to the detailed [REPORT.md](REPORT.md) document.